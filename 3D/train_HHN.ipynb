{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import random\n",
    "from dataset import ModelnetDataset\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from util import setup_seed, train, test, train_HHN, test_HHN, train_one4one, count_parameters, save_checkpoint\n",
    "from model import One4All, HyperNetwork\n",
    "from render import PointcloudRender\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 #  \n",
    "epochs = 6000 #\n",
    "best_acc1 = 0\n",
    "start_epoch = 0\n",
    "dimension = 6\n",
    "lr=0.006\n",
    "# \n",
    "from datetime import datetime\n",
    "import pytz\n",
    "today = datetime.now(pytz.timezone('Europe/Vienna')).strftime('%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(666)\n",
    "device_for_dataset = \"cuda:8\" if torch.cuda.is_available() else \"cpu\"\n",
    "writer = SummaryWriter(f'tf-logs/HHN/bs{batch_size}_lr{lr}_{int(epochs/1000)}k_D_{dimension}_hyperwide72')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preocessing train data in_mem = True and infor: Default infor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prepare train dataset categories: 100%|██████████| 10/10 [08:10<00:00, 49.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preocessing test data in_mem = True and infor: Default infor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prepare test dataset categories: 100%|██████████| 10/10 [01:30<00:00,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  3991\n",
      "Test dataset size:  908\n",
      "Number of classes:  10\n",
      "Class:  bathtub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = Path(\"./data\")\n",
    "train_ds = ModelnetDataset(path, folder=\"train\", device=device_for_dataset) # Just put dataset in mem or GPU\n",
    "test_ds = ModelnetDataset(path, folder=\"test\", device=device_for_dataset) # Just put dataset in mem or GPU\n",
    "classes = {i: cat for cat, i in train_ds.classes.items()}\n",
    "\n",
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Test dataset size: ', len(test_ds))\n",
    "print('Number of classes: ', len(train_ds.classes))\n",
    "print('Class: ', classes[train_ds[11]['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bathtub': 106, 'bed': 515, 'chair': 889, 'desk': 200, 'dresser': 200, 'monitor': 465, 'night_stand': 200, 'sofa': 680, 'table': 392, 'toilet': 344}\n",
      "{'bathtub': 50, 'bed': 100, 'chair': 100, 'desk': 86, 'dresser': 86, 'monitor': 100, 'night_stand': 86, 'sofa': 100, 'table': 100, 'toilet': 100}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(dict(Counter(sample['category'] for sample in train_ds.files)))\n",
    "\n",
    "print(dict(Counter(sample['category'] for sample in test_ds.files)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_path = f'checkpoint/HHN/{today}'\n",
    "# print(f'sdsdsdsd{day_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved in checkpoint/HHN/12-30/bs256_lr0.006_6k_D_6\n"
     ]
    }
   ],
   "source": [
    "day_path = f'checkpoint/HHN/{today}'\n",
    "\n",
    "model_checkpoints_path = f'{day_path}/bs{batch_size}_lr{lr}_{int(epochs/1000)}k_D_{dimension}'\n",
    "\n",
    "if not os.path.exists(day_path):\n",
    "    print(f'Creating {day_path} ...')\n",
    "    os.makedirs(day_path)\n",
    "if not os.path.exists(model_checkpoints_path):\n",
    "    print(f'Creating {model_checkpoints_path} ...')\n",
    "    os.makedirs(model_checkpoints_path)\n",
    "print(f'Models will be saved in {model_checkpoints_path}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of model parameter: 832314\n",
      "HyperNetwork(\n",
      "  (hyper_stack): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=72, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=72, out_features=6, bias=True)\n",
      "    (3): Softmax(dim=0)\n",
      "  )\n",
      "  (w_conv1_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 4x1x5x5 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 4x1x5x5 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 4x1x5x5 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 4x1x5x5 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 4x1x5x5 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 4x1x5x5 (GPU 8)]\n",
      "  )\n",
      "  (bias_conv1_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 4 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 4 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 4 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 4 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 4 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 4 (GPU 8)]\n",
      "  )\n",
      "  (w_conv2_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 16x4x5x5 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 16x4x5x5 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 16x4x5x5 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 16x4x5x5 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 16x4x5x5 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 16x4x5x5 (GPU 8)]\n",
      "  )\n",
      "  (bias_conv2_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 16 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 16 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 16 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 16 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 16 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 16 (GPU 8)]\n",
      "  )\n",
      "  (w_linear1_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 256x400 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 256x400 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 256x400 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 256x400 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 256x400 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 256x400 (GPU 8)]\n",
      "  )\n",
      "  (bias_linear1_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 256 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 256 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 256 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 256 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 256 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 256 (GPU 8)]\n",
      "  )\n",
      "  (w_linear2_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 128x256 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 128x256 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 128x256 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 128x256 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 128x256 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 128x256 (GPU 8)]\n",
      "  )\n",
      "  (bias_linear2_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 128 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 128 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 128 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 128 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 128 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 128 (GPU 8)]\n",
      "  )\n",
      "  (w_linear3_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 10x128 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 10x128 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 10x128 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 10x128 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 10x128 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 10x128 (GPU 8)]\n",
      "  )\n",
      "  (bias_linear3_list): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 10 (GPU 8)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 10 (GPU 8)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 10 (GPU 8)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 10 (GPU 8)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 10 (GPU 8)]\n",
      "      (5): Parameter containing: [torch.cuda.FloatTensor of size 10 (GPU 8)]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "best_filename = f'{model_checkpoints_path}/Best-bs{batch_size}_lr{lr}_{int(epochs/1000)}k_D_{dimension}-HHNcheckpoint.pth.tar'\n",
    "\n",
    "gpu_computation = \"cuda:8\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = HyperNetwork(dimensions=dimension, hidden_units=72)\n",
    "model = model.to(gpu_computation)\n",
    "print(f'Num of model parameter: {count_parameters(model)}')\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = 1e-6)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.004)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), 0.001,\n",
    "#                                 momentum=0.9,\n",
    "#                                 weight_decay=1e-4\n",
    "#                            )\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=5e-6)\n",
    "pr = PointcloudRender(              \n",
    "                 img_size=128,\n",
    "                 radius=0.0045,\n",
    "                 points_per_pixel=40,\n",
    "                 num_points = 4096)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "angles = torch.randint(-180, 180, (3,))/180*torch.pi\n",
    "print(f'Test angles: {angles}')\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(60*\"=\"+f\"\\n Epoch: {t + 1} \\n\"+60*\"=\")\n",
    "    # angles = torch.randint(-180, 180, (3,))/180*torch.pi\n",
    "    \n",
    "    train_acc, train_loss= train_HHN(train_loader, model, loss_fn, optimizer, t, pr, device=gpu_computation)\n",
    "    test_acc, test_loss = test_HHN(test_loader, model, loss_fn, pr, device=gpu_computation, angles=angles, verbose=False)\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, t)\n",
    "    writer.add_scalar(\"Accuracy/train\", train_acc, t)\n",
    "    \n",
    "    writer.add_scalar(\"Loss/test\", test_loss, t)\n",
    "    writer.add_scalar(\"Accuracy/test\", test_acc, t)\n",
    "    \n",
    "    is_best = test_acc > best_acc1\n",
    "    best_acc1 = max(test_acc, best_acc1)\n",
    "\n",
    "    if (t+1)%100 == 0:\n",
    "        save_checkpoint({\n",
    "        'epoch': t + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        }, is_best,\n",
    "        filename= f'{model_checkpoints_path}/E-{t}-bs{batch_size}_lr{lr}_{int(epochs/1000)}k_D_{dimension}-HHNcheckpoint.pth.tar', #saved_filename, #Todo add GPU and epoch information to the filename\n",
    "        best_filename = best_filename\n",
    "        )\n",
    "    writer.flush()\n",
    "    lr_scheduler.step()\n",
    "\n",
    "print(\"Done!\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Oct 18 2022, 18:57:03) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc7966a0b335081e18a4ba2e77526939bcb1adcbb1531a61cdd4d776909711b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
